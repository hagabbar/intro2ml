{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "MNIST is a handwrriten digit database with a training set of 60,000 examples and a test se of 10,000 examples. The images are all 28x28 and greyscale.\n",
    "\n",
    "It is available [here](http://yann.lecun.com/exdb/mnist/), but is included in Keras and will automatically download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3,3)\n",
    "axs = axs.ravel()\n",
    "for i in range(len(axs)):\n",
    "    axs[i].imshow(x_train[i].reshape(28,28), cmap='gray')\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the 'x' arrays are the images and the 'y' arrays are the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General parameters\n",
    "\n",
    "We need to define some general parameters for networks we're going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128    # number of images passed each iteration\n",
    "num_classes = 10    # digits 0 to 9\n",
    "epochs = 20         # number of full passes of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "This example uses a simple deep neural net (more than 1 layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an MLP the data needs to be parsed as 1D array, rather than a 2D image. \n",
    "\n",
    "So, the data is reshaped according to the number of samples (60,000 or 10,000) and the size of the image 784 (28x28).\n",
    "\n",
    "The data is then normalized (0,255) to (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# reshape data\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# normalize data\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is the content of the labels vectors looks like this:\n",
    "```\n",
    "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)\n",
    "```\n",
    "The NN expects them labels as binary class matrix instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the label for each image looks like this:\n",
    "```\n",
    "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()    # define the type of keras model\n",
    "# add first layer with dropout and relu activation\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "# add another layer\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "# add the output layer with softmax actiavtion for classication\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# print a summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.2460 - acc: 0.9259 - val_loss: 0.1047 - val_acc: 0.9686\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.1022 - acc: 0.9682 - val_loss: 0.0749 - val_acc: 0.9760\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0706 - acc: 0.9775 - val_loss: 0.0695 - val_acc: 0.9776\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0552 - acc: 0.9821 - val_loss: 0.0623 - val_acc: 0.9817\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0472 - acc: 0.9851 - val_loss: 0.0677 - val_acc: 0.9806\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 0.0370 - acc: 0.9878 - val_loss: 0.0671 - val_acc: 0.9816\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.0341 - acc: 0.9894 - val_loss: 0.0661 - val_acc: 0.9809\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 15s 242us/step - loss: 0.0312 - acc: 0.9901 - val_loss: 0.0654 - val_acc: 0.9817\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.0294 - acc: 0.9903 - val_loss: 0.0614 - val_acc: 0.9829\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 14s 225us/step - loss: 0.0237 - acc: 0.9920 - val_loss: 0.0820 - val_acc: 0.9805\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.0238 - acc: 0.9920 - val_loss: 0.0680 - val_acc: 0.9837\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 0.0198 - acc: 0.9933 - val_loss: 0.0762 - val_acc: 0.9819\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 14s 225us/step - loss: 0.0214 - acc: 0.9927 - val_loss: 0.0775 - val_acc: 0.9802\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0204 - acc: 0.9933 - val_loss: 0.0725 - val_acc: 0.9823\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 14s 232us/step - loss: 0.0174 - acc: 0.9943 - val_loss: 0.0744 - val_acc: 0.9809\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.0156 - acc: 0.9947 - val_loss: 0.0752 - val_acc: 0.9823\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0183 - acc: 0.9939 - val_loss: 0.0673 - val_acc: 0.9859\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 0.0168 - acc: 0.9944 - val_loss: 0.0697 - val_acc: 0.9851\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.0152 - acc: 0.9948 - val_loss: 0.0768 - val_acc: 0.9841\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.0152 - acc: 0.9953 - val_loss: 0.0765 - val_acc: 0.9838\n",
      "Test loss: 0.07650775185095608\n",
      "Test accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
